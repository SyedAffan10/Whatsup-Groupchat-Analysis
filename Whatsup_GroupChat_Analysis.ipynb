{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001ec10c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====================================================================\n",
      "\t \t \t Sentiment Score\n",
      " ====================================================================\n",
      "\t \t \t Positive: 23.83%\n",
      "\t \t \t Negative: 5.96%\n",
      "\t \t \t Neutral: 70.21%\n",
      "\n",
      " ====================================================================\n",
      "\t \t \t Positive Words\n",
      " ====================================================================\n",
      "['interesting', 'wins', 'real', 'real', 'better', 'free', 'becoming', 'Good', 'fine', 'more', 'fine', 'good', 'first', 'first', 'first', 'true', 'most', 'famous', 'win', 'new', 'Welcome', 'Much', 'Welcome', 'Welcome', 'Thanks', 'welcome', 'new', 'precious', 'right', 'good', 'fine', 'best', 'very', 'challenging', 'many', 'calm', 'very', 'very', 'grand', 'very', 'Fine', 'whole', 'busy', 'Okay', 'okay', 'Really', 'fine', 'Really', 'very', 'hot', 'Fine', 'fine', 'much', 'Thanks', 'Welcome', 'Okay', 'first', 'Good', 'Good', 'Good', 'Fine', 'Fine', 'Better', 'confirmed', 'right', 'busy', 'Okay', 'fine', 'fine', 'Outstanding', 'Fine', 'Fine']\n",
      "\n",
      " ====================================================================\n",
      "\t \t \t Negative Words\n",
      " ====================================================================\n",
      "['game', 'other', 'mean', 'hard', 'impossible', 'other', 'down', 'other', 'horrible', 'killed', 'horrible', 'badly', 'sad', 'bad', 'tired', 'destroy', 'broken', 'few', 'long']\n",
      "\n",
      " ====================================================================\n",
      "\t \t \t Neutral Words\n",
      " ====================================================================\n",
      "['\\u200eMessages', 'and', 'calls', 'are', 'end-to-end', 'encrypted', '.', 'No', 'one', 'outside', 'of', 'this', 'chat', ',', 'not', 'even', 'WhatsApp', ',', 'can', 'read', 'or', 'listen', 'to', 'them', '.', '\\u200eRimsha', 'Fyp', 'created', 'this', 'group', '\\u200eYou', 'joined', 'using', 'this', 'group', \"'s\", 'invite', 'link', '\\u200eYou', \"'re\", 'now', 'an', 'admin', 'Assalam', 'o', 'Alaikum', '!', 'every', 'body.Thanks', 'to', 'you', 'all', 'for', 'joining', 'our', 'group', '.', 'We', 'want', 'to', 'discuss', 'different', 'and', 'some', 'topics', 'in', 'which', 'I', 'hope', 'you', 'all', 'guys', 'would', 'like', 'to', 'participate', '.', 'So', ',', 'our', 'today', \"'s\", 'topic', 'is', 'politics', '.', 'Politics', 'is', 'the', 'way', 'that', 'group', 'of', 'people', 'makes', 'decisions', 'for', 'the', 'betterment', 'of', 'the', 'country', 'people', 'not', 'to', 'rule', 'the', 'people', '.', 'In', 'my', 'point', 'of', 'view', 'politics', 'is', 'a', 'in', 'which', 'on', 'lose', 'and', 'every', 'day', 'use', 'every', 'to', 'find', 'his', 'goal', '.', 'They', 'want', 'to', 'achieve', 'power', 'by', 'hook', 'or', 'by', 'crook', '.', 'These', 'days', 'politicians', 'do', 'politics', 'to', 'create', 'slave', 'to', 'rule', 'them', 'That', \"'s\", 'not', 'politics', 'that', \"'s\", 'there', 'perception', 'they', 'do', \"n't\", 'know', 'the', 'meaning', 'of', 'politics', 'I', 'think', 'so', 'that', 'the', 'meaning', 'of', 'politics', 'is', 'a', 'group', 'of', 'people', 'who', 'work', 'together', 'to', 'runs', 'the', 'affairs', 'of', 'country', 'in', 'way', '.....', 'But', 'now', 'different', 'political', 'parties', 'are', 'just', 'working', 'to', 'make', 'their', 'nation', 'slaves', 'They', 'just', 'want', 'to', 'earn', 'money', 'by', 'different', 'ways', 'and', 'that', \"'s\", 'it', '.....', 'Above', 'definitions', 'are', 'enough', 'to', 'define', 'politics', '.', 'Now', 'the', 'point', 'is', 'this', 'that', 'if', 'you', 'get', 'any', 'chance', 'to', 'vote', 'any', 'political', 'party', 'which', 'party', 'you', 'would', 'like', 'to', 'prefer', 'for', 'Pakistan', '?', 'I', 'would', 'like', 'to', 'vote', 'PTI', 'because', 'this', 'party', 'worked', 'alot', 'and', 'saved', 'alot', 'of', 'resources', 'and', 'wealth', 'for', 'Pakistan', '.', '@', 'everybody', 'Feel', 'to', 'tell', 'about', 'your', 'favourite', 'party.Nobody', 'will', 'creticize', 'you', 'I', 'would', 'like', 'to', 'vote', 'PTI', '(', 'Imran', 'Khan', ')', 'My', 'favourite', 'party', 'is', 'tehreek', 'e', 'insaf', 'For', 'improving', 'our', 'country', 'economics', 'and', 'giving', 'message', 'of', 'independent', 'in', 'our', 'thoughts', 'and', 'actions', 'I', 'would', 'like', 'to', 'vote', 'Tehreek', 'E', 'Labbaik‚ù§Ô∏è', 'I', \"'ll\", 'vote', 'for', 'pak', 'armyü§™', 'that', \"'s\", 'also', 'greatüòÉ', 'Yes', 'i', 'am', 'also', 'with', 'him', '...', 'For', 'One', 'and', 'only', 'Imran', 'khan', 'Assalam', 'o', 'Alaikum', '!', 'Everyone', 'How', 'are', 'you', 'all', '?', 'W', 'slm', 'F9', 'Walaikum', 'assalam', 'Alhmdulillah', 'Finee', 'Walaikum', 'assalam', 'Alhmdulilah', 'I', \"'m\", 'doing', 'well.Thanks', 'üòä', 'Salam', 'guys', 'please', 'introduce', 'your', 'self', 'one', 'by', 'one', 'so', 'in', 'the', 'end', 'we', 'have', 'conversation', 'for', 'our', 'project', 'Wa.salam', 'My', 'name', 'is', 'Rimsha', 'Batool.I', \"'m\", 'from', 'Jhamra.I', \"'m\", 'doing', 'mcs', 'from', 'Virtual', 'University', 'of', 'Pakistan', 'Wa.slm.I', \"'m\", 'Sania.Student', 'of', 'ICS', '.', 'Wa.salam', '.This', 'is', 'Zain', 'Ali', 'form', 'Jhamra', '.', 'Assalam', 'o', 'Alaikum', '!', 'To', 'all', 'group', 'members', '.', 'Walaikum', 'salam', 'How', 'are', 'you', 'guyz', 'I', \"'m\", 'What', \"'s\", 'about', 'you', '?', 'I', \"'m\", 'What', 'are', 'you', 'all', 'doing', 'now', 'a', 'days', '?', 'Are', 'you', 'guys', 'from', 'vu', 'Wa.slm', 'Fine.Thanks', 'Just', 'college', 'routine', 'is', 'going', 'on', 'No', ',', 'I', \"'m\", 'a', 'college', 'student', '.', 'Yes', ',', 'I', \"'m\", 'from', 'vu', '.', 'So', 'guys', 'I', \"'m\", 'starting', 'a', 'topic', 'for', 'today', 'The', 'topic', 'is', 'Imam', 'Ali', 'Of', 'course', 'let', \"'s\", 'start', 'Let', 'us', 'talk', 'about', 'imam', 'Ali', 'Hazrat', 'Ali', 'is', 'the', 'imam.He', 'is', 'cousin', 'of', 'Rasoolullah.He', 'was', 'son', 'of', 'Hazrat', 'Abu', 'Talib', 'who', 'was', 'rasoolullah', \"'s\", 'paternal', 'uncle', '.', 'The', 'imam', 'and', 'the', 'bravest', 'man', 'in', 'history', '.', 'Imam', 'Ali', 'is', 'the', 'man', 'who', 'accepts', 'Islam', 'At', 'the', 'age', 'of', '8', 'Yes', 'that', \"'s\", 'And', 'the', 'thing', 'is', 'that', 'he', 'was', 'born', 'in', 'Khana', 'kaba', 'and', 'died', 'in', 'Masjid', 'in', 'the', 'condition', 'when', 'he', 'was', 'offering', 'prayer', '.', 'RasulAllah', 'says', '``', 'Ali', 'is', 'fom', 'me', 'and', 'I', 'am', 'from', 'Ali', \"''\", ',', \"''\", 'Ali', 'you', 'are', 'my', 'brother', 'here', 'on', 'earth', 'and', 'in', 'jannah', \"''\", 'Holy', 'prophet', 'said', ',', '‚Äú', 'There', 'is', 'no', 'sword', 'but', 'Dhul-Fiqar', ',', 'and', 'there', 'is', 'no', 'man', 'but', 'Ali', '(', 'a.s', ')', '.', '‚Äù', 'Imam', 'Ali', 'was', 'the', 'one', 'who', 'khaiber', 'and', 'kill', 'marhab', 'Holy', 'Prophet', 'S.', 'A.', 'W', 'also', 'said', ',', 'I', 'am', 'the', 'city', 'of', 'knowledge', 'and', 'Ali', 'is', 'it', \"'s\", 'door', '.', '\\u200eYou', 'added', 'Usama', 'Hi', 'guys', 'this', 'is', 'our', 'member', 'Usama', 'Ali', '@', '923473762959', 'Thank', 'You', 'so', 'Mr', '@', '923473146786', 'for', 'Me', 'In', 'this', 'Group', 'in', 'this', 'group', 'for', 'joining', 'us', 'member', 'Salam', 'everyone', 'How', 'are', 'you', 'guys', 'Guys', 'we', 'need', 'lot', 'of', 'chat', 'for', 'aour', 'project', 'so', 'please', 'talk', 'here', 'and', 'share', 'you', 'experiences', 'of', 'your', 'life', 'and', 'work', 'Wa.slm', 'Fine.What', \"'s\", 'about', 'you', '?', 'Walaikum', 'assalam', 'Being', 'a', 'teacher', 'and', 'student', 'managing', 'alot', 'of', 'things', 'in', 'short', 'time', 'make', 'me', 'thinks', 'that', 'time', 'is', 'so', '.', 'So', ',', 'without', 'spoiling', 'a', 'minute', 'we', 'should', 'work', 'in', 'the', 'given', 'time', '.', '*', 'Nothing', 'is', 'in', 'this', 'world', '*', 'Yeah', 'I', \"'m\", 'Alhamdulillah', 'Anyone', 'else', 'Wa.slm', 'I', \"'m\", '.', 'How', 'are', 'you', '?', 'I', \"'m\", 'a', 'student', 'facing', 'alot', 'of', 'situations', 'during', 'this', 'time', 'period.So', ',', 'keeping', 'patience', 'is', 'the', 'thing', 'that', 'I', 'think', 'so', '.', 'W', 'slm', 'Alhamdulillah', 'What', 'about', 'you', '?', 'Goo', 'Alhamdulillah', 'I', 'am', 'also', 'agree', 'with', 'Rimsha', 'but', 'on', 'the', 'side', 'in', 'case', 'of', 'teacher', 'life', 'is', 'we', 'should', 'face', 'up', 'and', '.', 'Yes', 'we', 'all', 'should', 'know', 'to', 'have', 'patience', 'and', 'be', 'I', \"'m\", 'a', 'teacher.My', 'experience', 'in', 'teaching', 'teaches', 'me', 'alot', 'of', 'things.one', 'thing', 'that', 'I', 'want', 'to', 'share', 'is', 'compromise', '.', 'We', 'also', 'handle', 'the', 'students', 'along', 'with', 'their', 'parents', 'but', 'in', 'this', 'we', 'know', 'about', 'the', 'importance', 'of', 'time', 'and', 'also', 'learn', 'about', 'handling', 'the', 'activities', 'that', 'take', 'place', 'in', 'life', 'Salam', 'everybody', 'Have', 'you', 'all', 'listen', 'about', 'yesterday', \"'s\", 'kallar', 'kahar', 'accident', '?', 'W', 'slm', 'Yes', ',', 'I', 'heard', 'about', 'that.Really', 'A', 'accident', '13', 'people', '.', 'I', \"'m\", 'doing', 'well.What', \"'s\", 'about', 'you', 'dear', '?', 'Wa.slm', 'Yes', ',', 'I', 'have', 'also', 'come', 'to', 'know', 'about', 'that', 'Walaikum', 'salam', 'Who', 'is', 'he', 'Bus', 'was', 'traveling', 'from', 'Rawalpindi', 'to', 'Lahore.There', 'were', 'almost', '38', 'to', '40', 'passengers', '.', 'In', 'kallar', 'kahar', 'motor', 'way', 'salt', 'range', 'a', 'bus', 'accident', 'happened', 'yesterday', 'Oh', '!', 'That', 'was', 'seen.Brakes', 'were', 'fail.So', ',', 'thats', 'why', 'this', 'accident', 'happened', '.', 'I', 'heard.13', 'people', 'died', 'and', '25', 'people', 'are', 'injured', 'So', 'may', 'Allah', 'forgive', 'them', 'and', 'them', 'jannah', 'Ameen', 'RIP', 'Yes', ',', 'people', 'were', 'on', 'the', 'road', 'in', 'condition', 'Wa.slm', '....', 'It', \"'s\", 'also', 'being', 'noticed', 'by', 'police', 'that', 'there', 'was', 'some', 'issue', 'with', 'bus', 'they', 'stopped', 'and', 'warn', 'the', 'driver', 'about', 'that', '...', 'That', 'driver', 'checked', 'the', 'issue.He', 'knew', 'that', 'issue', 'was', 'big', 'but', 'instead', 'of', 'stopping', 'he', 'again', 'started', 'the', 'bus', 'Yes', ',', 'also', 'a', 'lesson', 'for', 'others', '....', 'Yes', 'I', 'know', 'about', 'that', 'accident', 'that', 'happened', 'yesterday', 'in', 'motorway', 'salt', 'range', 'kallar', 'kahar', '.', 'Salam', 'everybody', 'Wa.slm', 'Where', 'were', 'you', 'day', '?', 'I', 'was', 'just', 'in', 'exams', '.', 'Then', 'it', \"'s\", '.', 'I', 'was', 'wondering', 'that', 'it', \"'s\", 'a', 'miracle', 'that', 'you', 'are', 'offline', '.', 'Yes', 'Walaikum', 'salam', 'Assalam', 'o', 'Alaikum', '!', 'How', 'are', 'you', 'all', '?', 'Eid', 'is', 'coming', 'soon', 'so', ',', 'What', 'are', 'your', 'plans', 'about', 'eid', 'day', '?', 'Wa.slm', 'Fine.Thanks', 'As', 'you', 'know', 'girls', 'plans', 'during', 'this', 'eid', 'is', 'cooking', ',', 'washing', 'utensils', 'and', 'distributing', 'meetüòÉ', 'Meat', '*', 'Point', 'to', 'be', 'notedüòÉ', 'Walaikumassalam', 'Alhamdulillah', 'What', 'about', 'you', '?', 'No', 'mehndi', 'I', \"'m\", 'too', '....', 'ü§≠', '.', 'Now', 'weather', 'is', 'also', '.', 'So', ',', 'we', 'ca', \"n't\", 'go', 'for', 'outing', 'too', 'Gr8', 'Assalam', 'o', 'Alaikum', '!', 'How', 'are', 'you', 'all', '?', 'What', 'are', 'you', 'all', 'doing', 'these', 'days', '?', 'Wa.salam', '.', 'What', \"'s\", 'about', 'you', '?', 'Cooking', ',', 'eating', ',', 'washing', ',', 'sleeping', 'and', 'enjoyingüòÖ', 'I', \"'m\", 'also', '.', 'I', 'think', 'you', 'are', 'bore', 'and', 'nowüòÖ', 'Walaikumassalam', 'Alhamdulillah', 'What', 'about', 'you', 'Same', 'same', 'I', \"'m\", 'doing', 'well', 'OkayüòÉ', 'Nyxx', 'ü§ó', '\\u200eThis', 'message', 'was', 'deleted', '.', 'Salam', 'Do', 'you', 'all', 'know', 'about', 'titanic', 'Wa.slm', 'Yes', 'a', 'ship', 'whose', 'owner', 'claimed', 'it', 'as', 'a', 'biggest', 'ship', 'to', 'whome', 'no', 'one', 'could', 'Walaikum', 'assalam', 'And', 'on', 'its', 'journey', 'it', 'was', 'into', 'two', 'parts', 'Assalam', 'U', 'Alaikum', 'Guys', 'Morning', 'How', 'are', 'you', '?', 'Walaikum', 'salam', 'Alhamdulillah', 'how', 'are', 'you', 'bro', 'Wa.slm', 'morning', 'I', \"'m\", 'doing', 'well', 'What', \"'s\", 'about', 'you', '?', 'Wa.salam', 'morning', 'What', \"'s\", 'about', 'you', '?', 'Alhumdullah', 'Guys', 'What', \"'s\", 'About', 'BBQ', 'Plan', ',', 'Who', 'is', 'throwing', 'the', 'BBQ', 'party', '?', 'you', 'give', 'us', 'at', 'sukkar', 'multan', 'moterway', 'üòÇüòÇ', 'Why', 'not', 'bahria', 'TownüòÇüòÇ', 'Yeah', ',', 'after', 'days', 'may', 'be', '.', 'But', 'still', 'not', 'Yeah', '!', 'Same', 'like', 'Sania', 'Still', 'not', 'confirm', 'But', 'should', 'think', 'about', 'it.You', 'should', 'give', 'us', 'party', 'earlier', '.', 'üòÉüòÉ', 'Assalam', 'o', 'Alaikum', '!', '\\u200e', '<', 'attached', 'Walaikumassalam', 'How', 'are', 'you', 'and', 'what', 'are', 'you', 'doing', 'these', 'days', '?', 'Wa.salam', 'How', 'are', 'you', '?', 'Yeah', '!', 'Agree', 'Wa.slm', 'üíØ', 'Where', 'were', 'you', '?', 'After', 'a', 'time', 'period', 'you', 'are', 'here', '.', 'I', 'was', 'quite', '.', 'I', \"'m\", '&', 'what', 'about', 'you', '.........', '\\u200e', '<', 'attached', 'I', \"'m\", '.', '\\u200eThis', 'message', 'was', 'deleted', '.', 'Okay.Enjoy', 'dearüòç', 'Thnxx', 'My', 'pleasureüòç', 'üíØ', 'Assalam', 'o', 'Alaikum', '!', 'Walaikumassalam', 'How', 'are', 'you', '?', 'Walaikum', 'assalam', 'Wa.slm', '.', '\\u200e', '<', 'attached', 'https']\n",
      "\n",
      " ====================================================================\n",
      "\t \t \t Common Words\n",
      " ====================================================================\n",
      "[('.', 45), ('you', 41), ('I', 36), ('and', 29), ('is', 29), ('the', 28), ('to', 26), ('of', 24), (',', 24), ('?', 24)]\n",
      "\n",
      " ====================================================================\n",
      "\t \t \t Most Active User\n",
      " ====================================================================\n",
      "\t \t \t  Rimsha Fyp\n",
      "\n",
      " ====================================================================\n",
      "\t \t \t Per Day Messages\n",
      " ====================================================================\n",
      "          Date     Username  MessageCount\n",
      "0   01/07/2023   Rimsha Fyp             3\n",
      "1   01/07/2023   ~‚ÄØZain Ali             4\n",
      "2   02/07/2023   Rimsha Fyp             5\n",
      "3   02/07/2023   ~‚ÄØ........             6\n",
      "4   04/06/2023   Rimsha Fyp             1\n",
      "..         ...          ...           ...\n",
      "61  19/06/2023   Rimsha Fyp             3\n",
      "62  19/06/2023   ~‚ÄØZain Ali             6\n",
      "63  23/06/2023   Rimsha Fyp             8\n",
      "64  23/06/2023   ~‚ÄØ........             5\n",
      "65  23/06/2023   ~‚ÄØZain Ali             4\n",
      "\n",
      "[66 rows x 3 columns]\n",
      "\n",
      " ====================================================================\n",
      "\t \t \t Hourly Activity\n",
      " ====================================================================\n",
      "     Hour  Total Messages\n",
      "0   01 AM               3\n",
      "1   01 PM              18\n",
      "2   02 AM               1\n",
      "3   02 PM              25\n",
      "4   03 PM              23\n",
      "5   04 PM              29\n",
      "6   05 PM               4\n",
      "7   06 PM              15\n",
      "8   07 AM               5\n",
      "9   07 PM               3\n",
      "10  08 AM               2\n",
      "11  08 PM              10\n",
      "12  09 AM               2\n",
      "13  09 PM               4\n",
      "14  10 AM               9\n",
      "15  10 PM               3\n",
      "16  11 AM              56\n",
      "17  12 PM              16\n",
      "\n",
      " ====================================================================\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "# !pip install pandas\n",
    "# !pip install textblob\n",
    "\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Excel data into DataFrame\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    return df\n",
    "\n",
    "# Assign Sentiment Score\n",
    "def assign_sentiment_score(df):\n",
    "    def calculate_sentiment(message):\n",
    "        if isinstance(message, str):\n",
    "            return TextBlob(message).sentiment.polarity\n",
    "        else:\n",
    "            return 0  # Assign a neutral sentiment for non-string values\n",
    "        \n",
    "    df['Sentiment'] = df['Message'].apply(calculate_sentiment)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Extract Positive, Negative, and Neutral Words\n",
    "def extract_sentiment_words(df):\n",
    "    positive_words = []\n",
    "    negative_words = []\n",
    "    neutral_words = []\n",
    "\n",
    "    for message in df['Message']:\n",
    "        if isinstance(message, str):  # Check if the message is a string\n",
    "            words = word_tokenize(message)\n",
    "            for word in words:\n",
    "                if TextBlob(word).sentiment.polarity > 0:\n",
    "                    positive_words.append(word)\n",
    "                elif TextBlob(word).sentiment.polarity < 0:\n",
    "                    negative_words.append(word)\n",
    "                else:\n",
    "                    neutral_words.append(word)\n",
    "\n",
    "    return positive_words, negative_words, neutral_words\n",
    "\n",
    "\n",
    "# Extract Common and Most Used Words\n",
    "def extract_common_words(df):\n",
    "    all_words = []\n",
    "\n",
    "    for message in df['Message']:\n",
    "        if isinstance(message, str):  # Check if the message is a string\n",
    "            words = word_tokenize(message)\n",
    "            all_words.extend(words)\n",
    "\n",
    "    freq_dist = FreqDist(all_words)\n",
    "    common_words = freq_dist.most_common(10)  # Change the number as needed\n",
    "\n",
    "    return common_words\n",
    "\n",
    "\n",
    "# Most Active User\n",
    "def most_active_user(df):\n",
    "    most_active_user = df['Username'].value_counts().idxmax()\n",
    "    return most_active_user\n",
    "\n",
    "\n",
    "# Per Day Messages by Each Member\n",
    "def per_day_messages(df):\n",
    "    per_day_messages = df.groupby(['Date', 'Username']).size().reset_index(name='MessageCount')\n",
    "    return per_day_messages\n",
    "\n",
    "\n",
    "# Highly Active Time of the Day\n",
    "def hourly_activity(df):\n",
    "    df['Time'] = df['Time'].astype(str)\n",
    "    df = df[df['Time'] != 'nan']\n",
    "\n",
    "    # Create a copy of the DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    df_copy.loc[:, 'Hour'] = df_copy['Time'].apply(lambda x: f\"{int(x.split(':')[0]):02d} {x[-2:]}\")\n",
    "\n",
    "    # Group by 'Hour' and calculate the count of messages for each hour\n",
    "    hourly_activity = df_copy.groupby('Hour').size().reset_index(name='Total Messages')\n",
    "\n",
    "    # Create a new DataFrame with custom headings\n",
    "    result = pd.DataFrame({'Hour': hourly_activity['Hour'], 'Total Messages': hourly_activity['Total Messages']})\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main(file_path):\n",
    "    df = load_data(file_path)\n",
    "    \n",
    "    #sentiment_score\n",
    "    sentiment_score = assign_sentiment_score(df)\n",
    "    total_messages = len(sentiment_score)\n",
    "    positive_messages = sentiment_score[sentiment_score['Sentiment'] > 0]\n",
    "    negative_messages = sentiment_score[sentiment_score['Sentiment'] < 0]\n",
    "    neutral_messages = sentiment_score[sentiment_score['Sentiment'] == 0]\n",
    "    \n",
    "    percentage_positive = (len(positive_messages) / total_messages) * 100\n",
    "    percentage_negative = (len(negative_messages) / total_messages) * 100\n",
    "    percentage_neutral = (len(neutral_messages) / total_messages) * 100\n",
    "    \n",
    "    #positive_words, negative_words, neutral_words\n",
    "    positive_words, negative_words, neutral_words = extract_sentiment_words(df)\n",
    "    \n",
    "    #common_words\n",
    "    common_words = extract_common_words(df)\n",
    "    \n",
    "    #active_user\n",
    "    active_user = most_active_user(df)\n",
    "    \n",
    "    #per_day_msgs\n",
    "    per_day_msgs = per_day_messages(df)\n",
    "    \n",
    "    #hourly_act\n",
    "    hourly_act = hourly_activity(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"\\n ====================================================================\")\n",
    "    print(\"\\t \\t \\t Sentiment Score\")\n",
    "    print(\" ====================================================================\")\n",
    "    print(f\"\\t \\t \\t Positive: {percentage_positive:.2f}%\")\n",
    "    print(f\"\\t \\t \\t Negative: {percentage_negative:.2f}%\")\n",
    "    print(f\"\\t \\t \\t Neutral: {percentage_neutral:.2f}%\")\n",
    "    print(\"\\n ====================================================================\")\n",
    "    print(\"\\t \\t \\t Positive Words\")\n",
    "    print(\" ====================================================================\")\n",
    "    print(positive_words)\n",
    "    print(\"\\n ====================================================================\")\n",
    "    print(\"\\t \\t \\t Negative Words\")\n",
    "    print(\" ====================================================================\")\n",
    "    print(negative_words)\n",
    "    print(\"\\n ====================================================================\")\n",
    "    print(\"\\t \\t \\t Neutral Words\")\n",
    "    print(\" ====================================================================\")\n",
    "    print(neutral_words)\n",
    "    print(\"\\n ====================================================================\")\n",
    "    print(\"\\t \\t \\t Common Words\")\n",
    "    print(\" ====================================================================\")\n",
    "    print(common_words)\n",
    "    print(\"\\n ====================================================================\")\n",
    "    print(\"\\t \\t \\t Most Active User\")\n",
    "    print(\" ====================================================================\")\n",
    "    print(\"\\t \\t \\t\", active_user)\n",
    "    print(\"\\n ====================================================================\")\n",
    "    print(\"\\t \\t \\t Per Day Messages\")\n",
    "    print(\" ====================================================================\")\n",
    "    print(per_day_msgs)\n",
    "    print(\"\\n ====================================================================\")\n",
    "    print(\"\\t \\t \\t Hourly Activity\")\n",
    "    print(\" ====================================================================\")\n",
    "    print(hourly_act)\n",
    "    print(\"\\n ====================================================================\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    import nltk\n",
    "#     nltk.download('punkt')  # Download the tokenizer models\n",
    "    \n",
    "    file_path = \"./Downloads/Whatsup_groupchat_statistics/Chat1.xlsx\"\n",
    "    main(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75dc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
